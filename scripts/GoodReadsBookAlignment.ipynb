{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoodReadsBookAlignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/massivetexts/compare-tools/blob/master/scripts/GoodReadsBookAlignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLDXH9sOu1NL",
        "colab_type": "text"
      },
      "source": [
        "This notebook cross-references HathiTrust and GoodReads (via the USCD dataset), to find 'similar to' relationships. This can be used for training a different type of contextual relationship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFXF7-yhezzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz2ISjM8gJhg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "3bf2b077-8f20-4024-e412-11dac42d06c2"
      },
      "source": [
        "#@title Download Dataset Files - HathiFiles and USCD Book Data\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1LXpK1UfqtP89H1tYy0pBGHjYk8IhigUK\n",
        "!gdown https://drive.google.com/uc?id=19cdwyXwfXx_HDIgxXaHzH0mrx8nMyLvC\n",
        "!wget -O hathifiles.tsv.gz https://www.hathitrust.org/filebrowser/download/291721"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LXpK1UfqtP89H1tYy0pBGHjYk8IhigUK\n",
            "To: /content/goodreads_books.json.gz\n",
            "2.08GB [00:26, 77.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19cdwyXwfXx_HDIgxXaHzH0mrx8nMyLvC\n",
            "To: /content/goodreads_book_authors.json.gz\n",
            "17.9MB [00:00, 57.0MB/s]\n",
            "--2020-07-07 17:32:34--  https://www.hathitrust.org/filebrowser/download/291721\n",
            "Resolving www.hathitrust.org (www.hathitrust.org)... 134.68.125.197\n",
            "Connecting to www.hathitrust.org (www.hathitrust.org)|134.68.125.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1045306423 (997M) [application/octet-stream]\n",
            "Saving to: ‘hathifiles.tsv.gz’\n",
            "\n",
            "hathifiles.tsv.gz   100%[===================>] 996.88M  28.3MB/s    in 51s     \n",
            "\n",
            "2020-07-07 17:33:28 (19.6 MB/s) - ‘hathifiles.tsv.gz’ saved [1045306423/1045306423]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhnQkqUNmWCZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "4cf08f7a-11fe-47b4-f1b7-c892f62d9f84"
      },
      "source": [
        "# Mount Google Drive, for saving derived data.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "GRANT_FOLDER = '/content/drive/My Drive/Grants/IMLS Grant/Data/' #@param {type:'string'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z__kl7OLVwn7",
        "colab_type": "text"
      },
      "source": [
        "## Read HathiTrust Metadata\n",
        "\n",
        "Due to the size of the Hathifiles, create a chunk iterator, that only reads a part of the full dataset at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dExlX_ofSxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "487ed4f4-6477-4b76-c2b2-c4129cabad75"
      },
      "source": [
        "headings = ['htid', 'access', 'rights', 'ht_bib_key', 'description', 'source', \n",
        "            'source_bib_num', 'oclc_num', 'isbn', 'issn', 'lccn', 'title', \n",
        "            'imprint', 'rights_reason_code', 'rights_timestamp', 'us_gov_doc_flag', \n",
        "            'rights_date_used', 'pub_place', 'lang', 'bib_fmt', 'collection_code', \n",
        "            'content_provider_code', 'responsible_entity_code', \n",
        "            'digitization_agent_code', 'access_profile_code', 'author']\n",
        "# Dataset is large, so use an iterator\n",
        "htreader = pd.read_csv('hathifiles.tsv.gz', sep='\\t', compression='gzip',\n",
        "                     chunksize=100000, names=headings,\n",
        "                     usecols=['htid', 'author', 'title', 'rights_date_used',\n",
        "                               'description'])\n",
        "for htmeta in htreader:\n",
        "    example = htmeta.sample(4)\n",
        "    break\n",
        "example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>htid</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>rights_date_used</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20236</th>\n",
              "      <td>mdp.39015004074269</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lonely crusade.</td>\n",
              "      <td>1973.0</td>\n",
              "      <td>Himes, Chester B., 1909-1984.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79767</th>\n",
              "      <td>mdp.39015022356102</td>\n",
              "      <td>v.206 1956</td>\n",
              "      <td>Transactions.</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>Metallurgical Society of AIME.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51026</th>\n",
              "      <td>uc1.b4952868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Every child a wanted child : Clarence James Ga...</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>Williams, Doone.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40573</th>\n",
              "      <td>mdp.39015002706300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Popes Shakespeare-Ausgabe als Spiegel seiner K...</td>\n",
              "      <td>1975.0</td>\n",
              "      <td>Kowalk, Wolfgang.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     htid  ...                          author\n",
              "20236  mdp.39015004074269  ...   Himes, Chester B., 1909-1984.\n",
              "79767  mdp.39015022356102  ...  Metallurgical Society of AIME.\n",
              "51026        uc1.b4952868  ...                Williams, Doone.\n",
              "40573  mdp.39015002706300  ...               Kowalk, Wolfgang.\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc29LaaKixbD",
        "colab_type": "text"
      },
      "source": [
        "## Loading USCD data\n",
        "- read dataset file content (needs decompression)\n",
        "- parse json from content\n",
        "- loop through the books, and for each book, see if there is a match in our HathiTrust metadata DataFrame\n",
        "\n",
        "### Load Author Data and Cross-reference with HT\n",
        "\n",
        "First, we want to find the authors that are possible in the HathiTrust. Those that are not, we can ignore.\n",
        "\n",
        "This is a tricky alignment, because the HathiTrust author data is somewhat messy in it's formatting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PM1kQcTHKHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "8edfdbe6-2ae6-4508-b7dc-df56008c3f63"
      },
      "source": [
        "authors = pd.read_json('goodreads_book_authors.json.gz', compression='gzip', lines=True)\n",
        "authors.sample(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_rating</th>\n",
              "      <th>author_id</th>\n",
              "      <th>text_reviews_count</th>\n",
              "      <th>name</th>\n",
              "      <th>ratings_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156152</th>\n",
              "      <td>3.85</td>\n",
              "      <td>43127</td>\n",
              "      <td>738</td>\n",
              "      <td>Allan Bloom</td>\n",
              "      <td>10294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741264</th>\n",
              "      <td>5.00</td>\n",
              "      <td>7814838</td>\n",
              "      <td>2</td>\n",
              "      <td>Doc Underwood</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        average_rating  author_id  ...           name ratings_count\n",
              "156152            3.85      43127  ...    Allan Bloom         10294\n",
              "741264            5.00    7814838  ...  Doc Underwood             4\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwLXlTRoLRT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "3b83d956-4ff5-4fd7-e149-469b3b49a499"
      },
      "source": [
        "# Create a new lastname, firstname column in the USCD Authors Dataset\n",
        "authors['new_name'] = authors.name.str.replace('^(.*) ([A-Z].*)$', r'\\2, \\1')\n",
        "authors.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_rating</th>\n",
              "      <th>author_id</th>\n",
              "      <th>text_reviews_count</th>\n",
              "      <th>name</th>\n",
              "      <th>ratings_count</th>\n",
              "      <th>new_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>790587</th>\n",
              "      <td>2.00</td>\n",
              "      <td>3438740</td>\n",
              "      <td>1</td>\n",
              "      <td>Hector Giacomelli</td>\n",
              "      <td>1</td>\n",
              "      <td>Giacomelli, Hector</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65855</th>\n",
              "      <td>3.50</td>\n",
              "      <td>15581717</td>\n",
              "      <td>3</td>\n",
              "      <td>Gianluca Pirozzi</td>\n",
              "      <td>4</td>\n",
              "      <td>Pirozzi, Gianluca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343714</th>\n",
              "      <td>3.12</td>\n",
              "      <td>3078325</td>\n",
              "      <td>1</td>\n",
              "      <td>Victor Alvarez</td>\n",
              "      <td>8</td>\n",
              "      <td>Alvarez, Victor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        average_rating  author_id  ...  ratings_count            new_name\n",
              "790587            2.00    3438740  ...              1  Giacomelli, Hector\n",
              "65855             3.50   15581717  ...              4   Pirozzi, Gianluca\n",
              "343714            3.12    3078325  ...              8     Alvarez, Victor\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA0XUtaJMLYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9a8b25dd-46a8-48f2-a716-48497728d197"
      },
      "source": [
        "# Collect all the unique authors and unique book titles in the HathiTrust without\n",
        "# loading it all into memory\n",
        "\n",
        "import numpy as np\n",
        "all_ht_authors = []\n",
        "all_ht_titles = []\n",
        "for i, htmeta in enumerate(htreader):\n",
        "    print(i, end=',')\n",
        "    all_ht_authors.append(htmeta.author.unique())\n",
        "    all_ht_titles.append(htmeta.title.unique())\n",
        "print()\n",
        "all_ht_authors = pd.Series(np.concatenate(all_ht_authors)).drop_duplicates().fillna('')\n",
        "all_ht_titles = pd.Series(np.concatenate(all_ht_titles)).drop_duplicates().fillna('')\n",
        "all_ht_authors.shape, all_ht_titles.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16,25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "124,125,126,127,128,129,130,131,132,133,134,135,136,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "137,138,139,140,"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3314666,), (8557627,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_GlzmI3MK0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "123e490c-f696-4b19-db80-af3784d74ab7"
      },
      "source": [
        "# Reformat the author and book title information from the HathiTrust Metadata.\n",
        "# This won't be perfect, but we don't need completeness so the few places where \n",
        "# it messes up should be fine.\n",
        "!pip install -q git+git://github.com/massivetexts/compare-tools\n",
        "from compare_tools.hathimeta import clean_title\n",
        "\n",
        "def clean_author(x):\n",
        "    import re\n",
        "    x = re.sub('\\-?\\d\\d\\d\\d', '', x)\n",
        "    x = str(x).strip().strip('.')\n",
        "    x = x.split(',')[:2]\n",
        "    x = \",\".join(x)\n",
        "    return x\n",
        "\n",
        "def simple_title(x):\n",
        "    return (x.apply(clean_title)   # Run the compare_tools clean_title code\n",
        "             .str.lower()          # Lowercase\n",
        "             .str.split(r':|/|\\\\') # Split on :, /, \\\n",
        "             .apply(lambda x:x[0]) # Keep first string of split\n",
        "             .str.replace('\\W', '') # Only keep non-word chars\n",
        "             .apply(lambda x: x[:35]) # Truncate to first 35 chars\n",
        "    )\n",
        "all_ht_authors = all_ht_authors.apply(clean_author)\n",
        "clean_ht_titles = simple_title(all_ht_titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for Compare-Tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5fqa3Q3X1bs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "69613b8d-3bfe-4a6c-9ff6-9469bc26f336"
      },
      "source": [
        "clean_ht_titles.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2174967    forandagainstthestate\n",
              "3647964              feudafrique\n",
              "2559463     stilidiemancipazione\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tfvZ84YYqi9",
        "colab_type": "text"
      },
      "source": [
        "Here, I truncate the `authors` data. I rewrite the original variables to save memory.\n",
        "no reason to hold the entire original dataset in memory any more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ytgc0C9MO2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "63bc17e4-1ee8-4b9a-dc34-049cb8cbafdb"
      },
      "source": [
        "# Cross reference the HT Meta and the Goodreads data to find authors in both\n",
        "print(\"Checking Author Intersection\")\n",
        "a = set(all_ht_authors)\n",
        "b = set(authors.new_name)\n",
        "overlap = b.intersection(a)\n",
        "print(\"# of authors seen in both datasets:\", len(overlap))\n",
        "\n",
        "# Truncate Authors table\n",
        "print(\"Pre-size:\", authors.shape[0])\n",
        "authors = authors[authors.new_name.isin(overlap)]\n",
        "print(\"Post-size:\", authors.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Author Intersection\n",
            "# of authors seen in both datasets: 120407\n",
            "Pre-size: 829529\n",
            "Post-size: 120927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvpbxe3hZCjC",
        "colab_type": "text"
      },
      "source": [
        "## Load Book information for authors that may be in the HathiTrust\n",
        "\n",
        "First, the book data needs to be joined with authors, which has already been truncated to authors that we can find in the HathiTrust.\n",
        "\n",
        "Then, we derive a cleaned title and only keep the rows where there it matches the unique cleaned titles in the HathiTrust. This is saved to an CSV File in Google Docs called `merge_books.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucHb2LcAHW-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "969b98a5-9c92-4e6b-dc76-5b6c228db817"
      },
      "source": [
        "import os\n",
        "cols_to_keep = ['isbn', 'popular_shelves','similar_books', 'average_rating', 'link',\n",
        "                'publication_year', 'book_id', 'title', 'title_without_series',\n",
        "                'work_id', 'author_id', 'author', 'author_formatted', 'simple_title',\n",
        "                'edition_information']\n",
        "\n",
        "bookreader = pd.read_json('goodreads_books.json.gz', compression='gzip',\n",
        "                          lines=True, chunksize=100000)\n",
        "\n",
        "outf = os.path.join(GRANT_FOLDER, 'merge_books.csv.gz')\n",
        "\n",
        "for i, books in enumerate(bookreader):\n",
        "    print(i, end=', ')\n",
        "    # Extract the first author\n",
        "    books['first_author_id'] = books.authors.apply(lambda x: x[0]['author_id'] if len(x) > 0 else -1).astype(int)\n",
        "\n",
        "    # Do an inner join with authors. This will shrink the dataset\n",
        "    merged = books.merge(authors[['name', 'new_name', 'author_id']], \n",
        "                        how='inner', left_on='first_author_id', \n",
        "                        right_on='author_id')\n",
        "    # Clean the titles and only keep rows that have a matching title in the HT\n",
        "    merged['simple_title'] = simple_title(merged['title'].fillna(''))\n",
        "    merged = merged[merged.simple_title.isin(clean_ht_titles)]\n",
        "    merged = merged.rename(columns={'name': 'author', 'new_name': 'author_formatted'})\n",
        "\n",
        "    # Add to a list of dataframes, which will be concatenated together at the end.\n",
        "    merged[cols_to_keep].to_csv(outf, mode='a' if i > 0 else 'w', compression='gzip')\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F22HcffPq2HC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "0445146c-4ee7-4874-c8ff-f142a99a6170"
      },
      "source": [
        "## Get the book title overlap\n",
        "clean_gr_titles = set(np.concatenate([df.simple_title.unique() for df in pd.read_csv(outf, compression='gzip', chunksize=100000)]))\n",
        "cleaned_title_overlap = clean_gr_titles.intersection(clean_ht_titles)\n",
        "len(cleaned_title_overlap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (4,6,7,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FSNIu0mA46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "ae7cd33a-4683-4880-b7e0-cb8d1b157f58"
      },
      "source": [
        "nbooks = sum([df.shape[0] for df in pd.read_csv(outf, compression='gzip', chunksize=100000)])\n",
        "nbooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (4,6,7,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z8ASevqqbY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09090749-7a76-441f-efec-e709b9618e8d"
      },
      "source": [
        "htreader = pd.read_csv('hathifiles.tsv.gz', sep='\\t', compression='gzip',\n",
        "                     chunksize=250000, names=headings,\n",
        "                     usecols=['htid', 'author', 'title', 'rights_date_used',\n",
        "                               'description'])\n",
        "outht = os.path.join(GRANT_FOLDER, 'ht_overlap.csv.gz')\n",
        "for i, htmeta in enumerate(htreader):\n",
        "    htmeta['clean_author'] = htmeta.author.fillna('').apply(clean_author)\n",
        "    htmeta = htmeta[htmeta.clean_author.isin(overlap)]\n",
        "    htmeta['simple_title'] = simple_title(htmeta.title.fillna(''))\n",
        "    htmeta = htmeta[htmeta.simple_title.isin(cleaned_title_overlap)]\n",
        "    print(i, htmeta.shape[0])\n",
        "    htmeta.to_csv(outht, mode='a' if i > 0 else 'w', compression='gzip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 5028\n",
            "1 5477\n",
            "2 10739\n",
            "3 9488\n",
            "4 9082\n",
            "5 10084\n",
            "6 6286\n",
            "7 5274\n",
            "8 5658\n",
            "9 9218\n",
            "10 7678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11 8259\n",
            "12 6186\n",
            "13 8883\n",
            "14 6838\n",
            "15 7957\n",
            "16 3782\n",
            "17 3312\n",
            "18 5181\n",
            "19 2497\n",
            "20 1577\n",
            "21 5426\n",
            "22 7763\n",
            "23 8030\n",
            "24 5954\n",
            "25 5683\n",
            "26 11217\n",
            "27 18635\n",
            "28 12001\n",
            "29 5801\n",
            "30 7462\n",
            "31 4105\n",
            "32 4840\n",
            "33 4221\n",
            "34 5886\n",
            "35 17028\n",
            "36 2714\n",
            "37 6321\n",
            "38 10043\n",
            "39 3588\n",
            "40 7810\n",
            "41 4427\n",
            "42 6287\n",
            "43 5786\n",
            "44 5308\n",
            "45 2798\n",
            "46 2299\n",
            "47 6398\n",
            "48 7777\n",
            "49 5424\n",
            "50 3074\n",
            "51 1439\n",
            "52 2616\n",
            "53 4327\n",
            "54 4912\n",
            "55 7768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "56 7141\n",
            "57 3900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "58 4154\n",
            "59 5965\n",
            "60 5026\n",
            "61 4287\n",
            "62 3204\n",
            "63 3339\n",
            "64 2615\n",
            "65 9543\n",
            "66 5223\n",
            "67 3666\n",
            "68 3415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEHjb048uIYb",
        "colab_type": "text"
      },
      "source": [
        "At this point, we have the Goodreads book data with titles and authors that may be in HT, and vice-versa. That was easier computation.\n",
        "\n",
        "Now that we have smaller datasets, we can align where the title+author are identical *together*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceGGQXywrsfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6237191e-5467-4f5f-fb02-65de6d7eb782"
      },
      "source": [
        "sum([df.shape[0] for df in pd.read_csv(outht, compression='gzip', chunksize=100000)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "425198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n-zq-AmtYBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "htdf = pd.read_csv(outht, compression='gzip')\n",
        "gtdf = pd.read_csv(outf, compression='gzip')\n",
        "\n",
        "# Combine author + title into a single string, for simplicity\n",
        "gtdf['code'] = gtdf['author_formatted'] + '__' + gtdf['simple_title']\n",
        "htdf['code'] = htdf['clean_author'] + '__' + htdf['simple_title']\n",
        "\n",
        "# Dictionaries are fast for lookups\n",
        "book_id_code_ref = gtdf.set_index('book_id').code.to_dict()\n",
        "htid_code_ref = htdf.set_index('htid').code.to_dict()\n",
        "\n",
        "# Do an inner join, to only keep where the codes overlap\n",
        "gtdf = gtdf.merge(htdf['code'].drop_duplicates(),\n",
        "                  how='inner', on='code')\n",
        "\n",
        "htdf = htdf.merge(gtdf['code'].drop_duplicates(),\n",
        "                  how='inner', on='code')\n",
        "\n",
        "# Overwrite earlier files\n",
        "gtdf.to_csv(outf, mode='w', compression='gzip')\n",
        "htdf.to_csv(outht, mode='w', compression='gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2lIMHrpADOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "# Parse string of similar works into an actual list, and filter\n",
        "# to remove book_ids that are no longer in the dataset\n",
        "gtdf.book_id = gtdf.book_id.astype(int)\n",
        "unique_bookids = set(gtdf.book_id)\n",
        "def parse_list(x):\n",
        "    if x == \"[]\":\n",
        "        return []\n",
        "    else:\n",
        "        l = x[1:-1].split(', ')\n",
        "        return [int(y[1:-1]) for y in l]\n",
        "\n",
        "def filter_bookids(x):\n",
        "    m = set(x).intersection(unique_bookids)\n",
        "    return list(m)\n",
        "\n",
        "gtdf.similar_books = gtdf.similar_books.apply(parse_list).apply(filter_bookids)\n",
        "# Drop any rows without recommendations\n",
        "gtdf = gtdf[gtdf['similar_books'].apply(lambda x:len(x)) > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFJ3peU8k17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine lists of similar_books, parse to use a+t codes. Also combine book_ids\n",
        "def concat(x):\n",
        "    sim_books = [id for l1 in x.similar_books.tolist() for id in l1]\n",
        "    sim_books = list(set(sim_books))\n",
        "    sim_book_codes = [book_id_code_ref[str(x)] for x in sim_books]\n",
        "    return pd.Series({'similar_books':sim_book_codes, 'book_ids': x.book_id.tolist()})\n",
        "\n",
        "by_code = gtdf.reset_index().groupby(['code'])[['book_id', 'similar_books']].apply(concat)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KguZZGgdN0aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "outputId": "906e28a4-f54c-4138-975c-254aa8a7694c"
      },
      "source": [
        "htid_by_code = htdf.groupby('code')['htid'].apply(lambda x: x.tolist())\n",
        "by_code = by_code.merge(htid_by_code, left_index=True, right_index=True)\n",
        "by_code['similar_htids'] = by_code.similar_books.apply(lambda x: list(set([l for z in [htid_by_code[y] for y in x] for l in z])))\n",
        "by_code.sample(10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similar_books</th>\n",
              "      <th>book_ids</th>\n",
              "      <th>htid</th>\n",
              "      <th>similar_htids</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Williams, Charles__theplaceofthelion</th>\n",
              "      <td>[Carpenter, Humphrey__theinklings]</td>\n",
              "      <td>[143226, 1732118]</td>\n",
              "      <td>[mdp.39015066681407, uc1.$b391206, mdp.3901500...</td>\n",
              "      <td>[mdp.39015002385162, mdp.39015002385006]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Walton, Anthony__mississippi</th>\n",
              "      <td>[Barfield, Owen__historyinenglishwords, Lerer,...</td>\n",
              "      <td>[178784]</td>\n",
              "      <td>[mdp.39015037261107, uva.x002712367]</td>\n",
              "      <td>[mdp.39076006122779, inu.30000037449935, mdp.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tindall, Blair__mozartinthejungle</th>\n",
              "      <td>[Piston, Walter__harmony]</td>\n",
              "      <td>[34684275, 24998, 24752265, 19793474, 1473248]</td>\n",
              "      <td>[mdp.39015061459205]</td>\n",
              "      <td>[uc1.b4325083]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mayer, Mercer__justgrandpaandme</th>\n",
              "      <td>[Piven, Hanoch__mydogisassmellyasdirtysocks, D...</td>\n",
              "      <td>[633709]</td>\n",
              "      <td>[pst.000032698923]</td>\n",
              "      <td>[pst.000033005577, pst.000061597174]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Efremov, Ivan Antonovich__andromedaaspaceagetale</th>\n",
              "      <td>[Tolstoy, Aleksey Nikolayevich__aelita, Harris...</td>\n",
              "      <td>[26823107]</td>\n",
              "      <td>[mdp.39015046367887, mdp.39015038020460, uc1.$...</td>\n",
              "      <td>[pst.000000948081, uc1.b3462022, uiug.30112093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fiell, Charlotte__1000chairs</th>\n",
              "      <td>[Macaulay, David__buildingbig]</td>\n",
              "      <td>[1083029]</td>\n",
              "      <td>[mdp.39015056309894]</td>\n",
              "      <td>[mdp.39015049724571]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hyde, Catherine Ryan__electricgod</th>\n",
              "      <td>[Howatch, Susan__thewonderworker, Tiffany, Car...</td>\n",
              "      <td>[217450, 16124215]</td>\n",
              "      <td>[mdp.49015003325322]</td>\n",
              "      <td>[uva.x006112947, inu.30000103141119, mdp.39015...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Proust, Marcel__thecompleteshortstoriesofmarcelprou</th>\n",
              "      <td>[Beckett, Samuel__proust, Deleuze, Gilles__pro...</td>\n",
              "      <td>[1770405, 28394]</td>\n",
              "      <td>[mdp.39015050755985, mdp.39015070703452]</td>\n",
              "      <td>[mdp.39015005323111, mdp.39015008690995, mdp.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Duras, Marguerite__lapluiedété</th>\n",
              "      <td>[Cendrars, Blaise__gold, D'Aguiar, Fred__feedi...</td>\n",
              "      <td>[1147388]</td>\n",
              "      <td>[mdp.39015017018352]</td>\n",
              "      <td>[mdp.39015008513734, uc1.b3757121, mdp.3901506...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Newman, John Henry__apologiaprovitasua</th>\n",
              "      <td>[Belloc, Hilaire__thegreatheresies, Adam, Karl...</td>\n",
              "      <td>[43958, 1432861, 982471, 20613395, 18187394, 3...</td>\n",
              "      <td>[uc2.ark:/13960/t39z92w3d, mdp.39015008498209,...</td>\n",
              "      <td>[pst.000023794283, uc1.$b51909, uva.x000531104...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                        similar_books  ...                                      similar_htids\n",
              "code                                                                                                   ...                                                   \n",
              "Williams, Charles__theplaceofthelion                               [Carpenter, Humphrey__theinklings]  ...           [mdp.39015002385162, mdp.39015002385006]\n",
              "Walton, Anthony__mississippi                        [Barfield, Owen__historyinenglishwords, Lerer,...  ...  [mdp.39076006122779, inu.30000037449935, mdp.3...\n",
              "Tindall, Blair__mozartinthejungle                                           [Piston, Walter__harmony]  ...                                     [uc1.b4325083]\n",
              "Mayer, Mercer__justgrandpaandme                     [Piven, Hanoch__mydogisassmellyasdirtysocks, D...  ...               [pst.000033005577, pst.000061597174]\n",
              "Efremov, Ivan Antonovich__andromedaaspaceagetale    [Tolstoy, Aleksey Nikolayevich__aelita, Harris...  ...  [pst.000000948081, uc1.b3462022, uiug.30112093...\n",
              "Fiell, Charlotte__1000chairs                                           [Macaulay, David__buildingbig]  ...                               [mdp.39015049724571]\n",
              "Hyde, Catherine Ryan__electricgod                   [Howatch, Susan__thewonderworker, Tiffany, Car...  ...  [uva.x006112947, inu.30000103141119, mdp.39015...\n",
              "Proust, Marcel__thecompleteshortstoriesofmarcel...  [Beckett, Samuel__proust, Deleuze, Gilles__pro...  ...  [mdp.39015005323111, mdp.39015008690995, mdp.3...\n",
              "Duras, Marguerite__lapluiedété                      [Cendrars, Blaise__gold, D'Aguiar, Fred__feedi...  ...  [mdp.39015008513734, uc1.b3757121, mdp.3901506...\n",
              "Newman, John Henry__apologiaprovitasua              [Belloc, Hilaire__thegreatheresies, Adam, Karl...  ...  [pst.000023794283, uc1.$b51909, uva.x000531104...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgJ50Yl7UZZ0",
        "colab_type": "text"
      },
      "source": [
        "# Save Data\n",
        "\n",
        "This data fits better as JSON, because of the lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOLaFaWmUheo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "simspath = os.path.join(GRANT_FOLDER, 'good_reads_sims.json.gz')\n",
        "with gzip.GzipFile(simspath, 'w') as fout:\n",
        "    fout.write(by_code.reset_index().to_json(orient='records', lines=True).encode('utf-8'))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay4SrRm9z2Cg",
        "colab_type": "text"
      },
      "source": [
        "Potentially also useful - the data exploded into all left/right permutations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPlEswNztts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "2ced2306-091d-4283-8dfa-7d1593a5a116"
      },
      "source": [
        "import gzip\n",
        "with gzip.open('pairwise_gr_stats.json.gz', mode='w') as f:\n",
        "    f.write('left\\tright\\n'.encode('utf-8'))    \n",
        "    for i, (ind, row) in enumerate(by_code.iterrows()):\n",
        "        try:\n",
        "            pairs = [(htid, htid2) for htid in row['htid'] for htid2 in row['similar_htids']]\n",
        "            for pair in pairs:\n",
        "                out = json.dumps(dict(left=pair[0], right=pair[1], relationship='GRSIM')) +'\\n'\n",
        "                f.write(out.encode('utf-8'))\n",
        "        except:\n",
        "            print('Error with ', pair)\n",
        "        if i % 1000 == 0:\n",
        "            print(i)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulJ4L9xEKHN_",
        "colab_type": "text"
      },
      "source": [
        "If trimming the set downstream, sample then sort by left, rather than leaving unordered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSXZO21Jd1E4",
        "colab_type": "text"
      },
      "source": [
        "#### Workspace\n",
        "\n",
        "Reloading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdMFqdI1dzq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "simspath = os.path.join(GRANT_FOLDER, 'good_reads_sims.json.gz')\n",
        "df = pd.read_json(simspath, compression='gzip', lines=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmdS1ixteX7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b007909e-eb25-4f75-a57f-5ac6db043ede"
      },
      "source": [
        "# These are the HTIDs that needs to be crunched for training\n",
        "unique_htids = set([htid for htids in df.htid for htid in htids] + [htid for htids in df.similar_htids for htid in htids])\n",
        "len(unique_htids)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iu1QatfNag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.Series(list(unique_htids)).sample(frac=1).to_csv(os.path.join(GRANT_FOLDER, 'goodreads_htids.csv'), index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}