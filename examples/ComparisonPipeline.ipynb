{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Pipeline\n",
    "\n",
    "Input:\n",
    "    For each target, a comparison candidate from Annoy\n",
    "    \n",
    "Output:\n",
    "    For each target-candidate pair, export a series of content-based stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from compare_tools.hathimeta import HathiMeta, get_json_meta\n",
    "from compare_tools.configuration import config, init_htid_args\n",
    "from compare_tools.comparison import Comparison, HTIDComparison\n",
    "from compare_tools.utils import HTID\n",
    "htid_args = init_htid_args(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = HTID('hvd.ah4wfm', **htid_args) # College Sermons + A Set of Parish Sermons\n",
    "right = HTID('hvd.ah4wfn', **htid_args) # just College Sermons\n",
    "comp = HTIDComparison(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leftpagecount': 650,\n",
       " 'rightpagecount': 372,\n",
       " 'pageDiff': 278,\n",
       " 'pagePropDiff': 0.4276923076923077}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.stat_pagecounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LeftSize': 35,\n",
       " 'RightSize': 21,\n",
       " 'minSize': 21,\n",
       " 'LeftMeanMinSim': 0.02976813654306945,\n",
       " 'RightMeanMinSim': 0.002212450008465155,\n",
       " 'MeanSim': 0.046355374307591714,\n",
       " 'LeftTruncSim': 0.0022332966767536966,\n",
       " 'RightTruncSim': 0.002212450008465155,\n",
       " 'LeftPropThresh001': 0.6,\n",
       " 'LeftPropThresh003': 0.9428571428571428,\n",
       " 'LeftPropThresh005': 0.9714285714285714,\n",
       " 'LeftPropThresh008': 0.9714285714285714,\n",
       " 'RightPropThresh001': 1.0,\n",
       " 'RightPropThresh003': 1.0,\n",
       " 'RightPropThresh005': 1.0,\n",
       " 'RightPropThresh008': 1.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.stat_simmat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SW0020Len': 22, 'SW0005Len': 22}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.stat_sw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leftpagecount': 129,\n",
       " 'rightpagecount': 454,\n",
       " 'pageDiff': -325,\n",
       " 'pagePropDiff': -2.5193798449612403,\n",
       " 'SW0020Len': 0,\n",
       " 'SW0005Len': 0,\n",
       " 'LeftSize': 22,\n",
       " 'RightSize': 43,\n",
       " 'minSize': 22,\n",
       " 'LeftMeanMinSim': 0.1665143436005689,\n",
       " 'RightMeanMinSim': 0.2025905484694421,\n",
       " 'MeanSim': 0.32586165542979595,\n",
       " 'RightTruncSim': 0.1721637839941062,\n",
       " 'LeftTruncSim': 0.1665143436005689,\n",
       " 'LeftPropThresh001': 0.0,\n",
       " 'LeftPropThresh003': 0.0,\n",
       " 'LeftPropThresh005': 0.0,\n",
       " 'LeftPropThresh008': 0.0,\n",
       " 'RightPropThresh001': 0.0,\n",
       " 'RightPropThresh003': 0.0,\n",
       " 'RightPropThresh005': 0.0,\n",
       " 'RightPropThresh008': 0.0,\n",
       " 'left': 'aeu.ark:/13960/t1zc8d06f',\n",
       " 'right': 'hvd.32044106449234'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all at once\n",
    "comp.all_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other potential stats\n",
    "- jaccard sim\n",
    "- How many unique words are there?\n",
    "- sims by page, by SRP\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example crunching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from htrc_features import utils\n",
    "annmatches = glob.glob('/projects/saddl-main/ann-ef/matches/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To raise on warnings while debugging\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('error')\n",
    "    #do_something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 aeu.ark:/13960/t0000vt1c 0.05006051063537598\n"
     ]
    }
   ],
   "source": [
    "stats_collector = []\n",
    "i = 0 \n",
    "start = time.time()\n",
    "\n",
    "for matchfile in annmatches:\n",
    "    df = pd.read_parquet(matchfile)\n",
    "    df = df[(df.prop_target > 0.5) | (df.prop_match > 0.5)]\n",
    "    df = df[df['count'] > 1]\n",
    "    df = df[df.match != df.target]\n",
    "    \n",
    "    for target, matches in df.groupby('target'):\n",
    "        if i % 1000 == 0:\n",
    "            print(i, len(stats_collector), target, time.time()-start)\n",
    "        left = HTID(target, **htid_args)\n",
    "        \n",
    "        for match in matches['match']:\n",
    "            right = HTID(match, **htid_args)\n",
    "            comp = HTIDComparison(left, right)\n",
    "            try:\n",
    "                stats_collector.append(comp.all_stats())\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                print(\"Issue with \", left.htid, right.htid)\n",
    "\n",
    "        if len(stats_collector) > 10000:\n",
    "            pd.DataFrame(stats_collector).to_parquet('/data/saddl/tmp-comp-output/4' + utils.clean_htid(target) + 'andmore.parquet', compression='snappy')\n",
    "            stats_collector = []\n",
    "\n",
    "        i += 1\n",
    "pd.DataFrame(stats_collector).to_parquet('/data/saddl/tmp-comp-output/4' + utils.clean_htid(target) + 'andmore.parquet', compression='snappy')\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get rough ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T0A1P0O0C0D2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judge_meta(l,r):\n",
    "    judge_code = \"\"\n",
    "    \n",
    "    if l['title'] == r['title']:\n",
    "        judge_code += \"T1\"\n",
    "    elif l['title'][:20] == r['title'][:20]:\n",
    "        judge_code += \"T2\"\n",
    "    else:\n",
    "        judge_code += \"T0\"\n",
    "        \n",
    "    for char, field in [('A', 'author'), ('P', 'rights_date_used'), ('O', 'oclc_num')]:\n",
    "        if l[field] == r[field]:\n",
    "            judge_code += char + \"1\"\n",
    "        else:\n",
    "            judge_code += char + \"0\"\n",
    "        \n",
    "    if l['page_count'] == r['page_count']: \n",
    "        judge_code += \"C1\"\n",
    "    elif abs(l['page_count'] - r['page_count']) < 10:\n",
    "        judge_code += \"C2\"\n",
    "    elif abs(l['page_count'] - r['page_count']) < 20:\n",
    "        judge_code += \"C3\"\n",
    "    else:\n",
    "        judge_code += \"C0\"\n",
    "    \n",
    "    if not l['description'] and not r['description']:\n",
    "        judge_code += \"D2\"\n",
    "    elif not l['description'] or not r['description']:\n",
    "        judge_code += \"D3\"\n",
    "    elif (l['description'] == r['description']):\n",
    "        judge_code += \"D1\"\n",
    "    else:\n",
    "        judge_code += \"D0\"\n",
    "\n",
    "    return judge_code\n",
    "\n",
    "judge_meta(left.meta().to_dict(), right.meta().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 63.76490330696106\n",
      "2000 127.59842824935913\n",
      "3000 191.3848659992218\n",
      "4000 254.9635157585144\n",
      "5000 318.5099902153015\n",
      "6000 382.25969433784485\n",
      "7000 446.05241680145264\n",
      "8000 509.6741111278534\n",
      "9000 573.5247383117676\n",
      "10000 636.906721830368\n",
      "11000 700.0996561050415\n",
      "12000 763.8884723186493\n",
      "13000 827.3452496528625\n",
      "14000 890.7076849937439\n",
      "15000 954.1151504516602\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fields = ['title', 'author', 'rights_date_used', 'oclc_num', 'page_count', 'description']\n",
    "meta = htid_args['hathimeta']\n",
    "paths= glob.glob('/data/saddl/tmp-comp-output/*')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for path in paths:\n",
    "    collector = []\n",
    "    df = pd.read_parquet(path, columns=['left', 'right'])\n",
    "    for j, row in df.iterrows():\n",
    "        lmeta = meta.get_volume(row.left, fields)\n",
    "        rmeta = meta.get_volume(row.right, fields)\n",
    "        try:\n",
    "            meta_code = judge_meta(lmeta, rmeta)\n",
    "        except:\n",
    "            print('err')\n",
    "        collector.append((row.left, row.right, meta_code))\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i, time.time()-start)\n",
    "    outpath = path.replace('tmp-comp-output', 'tmp-ground-truth')\n",
    "    pd.DataFrame(collector, columns=['left', 'right', 'meta_code']).to_parquet(outpath)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700577"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for path in paths:\n",
    "    i += pd.read_parquet(path).shape[0]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
